{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybtex\n",
    "import pandas as pd\n",
    "import json\n",
    "import traceback\n",
    "from pybtex.database.input import bibtex\n",
    "\n",
    "bib_path = 'anthology+abstracts.bib'\n",
    "#open a bibtex file\n",
    "parser = bibtex.Parser()\n",
    "bibdata = parser.parse_file(bib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>title</th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Corpus based {A}mharic sentiment lexicon gener...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Negation handling for {A}mharic sentiment clas...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Embedding Oriented Adaptable Semantic Annotati...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Similarity and Farness Based Bidirectional Neu...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Large Vocabulary Read Speech Corpora for Four ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstract_id                                              title sentences  \\\n",
       "0            0  Corpus based {A}mharic sentiment lexicon gener...      2020   \n",
       "1            1  Negation handling for {A}mharic sentiment clas...      2020   \n",
       "2            2  Embedding Oriented Adaptable Semantic Annotati...      2020   \n",
       "3            3  Similarity and Farness Based Bidirectional Neu...      2020   \n",
       "4            4  Large Vocabulary Read Speech Corpora for Four ...      2020   \n",
       "\n",
       "                                              labels  \n",
       "0  Proceedings of the The Fourth Widening Natural...  \n",
       "1  Proceedings of the The Fourth Widening Natural...  \n",
       "2  Proceedings of the The Fourth Widening Natural...  \n",
       "3  Proceedings of the The Fourth Widening Natural...  \n",
       "4  Proceedings of the The Fourth Widening Natural...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index = 0\n",
    "total_list = []\n",
    "for bib_id in bibdata.entries:\n",
    "    tmp_list = []\n",
    "    b = bibdata.entries[bib_id].fields\n",
    "    try:\n",
    "        ab = b['abstract']\n",
    "        tmp_list.append(index)\n",
    "        tmp_list.append(b['title'])\n",
    "        tmp_list.append(b[\"year\"])\n",
    "        try:\n",
    "            tmp_list.append(b[\"booktitle\"])\n",
    "        except:\n",
    "            try:\n",
    "                tmp_list.append(b[\"journal\"])\n",
    "            except:\n",
    "                tmp_list.append('N/A')\n",
    "        \n",
    "        sentences = [str(i) for i in list(nlp(ab).sents) if len(str(i)) >= 3]\n",
    "        \n",
    "        if len(sentences) >=3:\n",
    "            total_list.append(tmp_list)\n",
    "        index += 1\n",
    "    except:\n",
    "        pass\n",
    "    if index % 500 == 0:\n",
    "        print(index)\n",
    "    \n",
    "total_df = pd.DataFrame(total_list, columns = ['abstract_id', 'title', 'year', 'booktitle'])\n",
    "# print(total_df.shape)\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.columns = ['abstract_id', 'title', 'year', 'booktitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>abs_sents</th>\n",
       "      <th>abs_sents_num</th>\n",
       "      <th>sent_order</th>\n",
       "      <th>background_sents</th>\n",
       "      <th>background_sent_num</th>\n",
       "      <th>background_sent_index</th>\n",
       "      <th>method_sents</th>\n",
       "      <th>method_sent_num</th>\n",
       "      <th>method_sent_index</th>\n",
       "      <th>result_sents</th>\n",
       "      <th>result_sent_num</th>\n",
       "      <th>result_sent_index</th>\n",
       "      <th>objective_sents</th>\n",
       "      <th>objective_sent_num</th>\n",
       "      <th>objective_sent_index</th>\n",
       "      <th>other_sents</th>\n",
       "      <th>other_sent_num</th>\n",
       "      <th>other_sent_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Sentiment classification is an active resear...</td>\n",
       "      <td>10</td>\n",
       "      <td>['background_label', 'background_label', 'back...</td>\n",
       "      <td>['Sentiment classification is an active resear...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>['Small set of seed terms are manually prepare...</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 6, 7, 8]</td>\n",
       "      <td>['Finally, the lexicon generated in corpus bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>[9]</td>\n",
       "      <td>['The intention of this approach is to handle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['User generated content is bringing new aspec...</td>\n",
       "      <td>9</td>\n",
       "      <td>['background_label', 'background_label', 'back...</td>\n",
       "      <td>['User generated content is bringing new aspec...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>['The proposed framework combines the lexicon ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>['The system is performing the best of all mod...</td>\n",
       "      <td>2</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>['For this research, we proposed Amharic negat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>['The Web has become a source of information, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>['background_label', 'background_label', 'meth...</td>\n",
       "      <td>['The Web has become a source of information, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>['Thus, this research work designed generic an...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 3, 5]</td>\n",
       "      <td>['The results have also implied that neural ne...</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>['In natural language one idea can be conveyed...</td>\n",
       "      <td>5</td>\n",
       "      <td>['background_label', 'background_label', 'back...</td>\n",
       "      <td>['In natural language one idea can be conveyed...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>['Accordingly, we proposed deep learning based...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3]</td>\n",
       "      <td>['The experiment on limited Amharic NLI datase...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>['Automatic Speech Recognition (ASR) is one of...</td>\n",
       "      <td>9</td>\n",
       "      <td>['background_label', 'background_label', 'back...</td>\n",
       "      <td>['Automatic Speech Recognition (ASR) is one of...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>['Amharic, Tigrigna, Oromo, and Wolaytta.', 'I...</td>\n",
       "      <td>4</td>\n",
       "      <td>[4, 5, 6, 7]</td>\n",
       "      <td>['we achieved show that the corpora are usable...</td>\n",
       "      <td>1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstract_id                                          abs_sents  \\\n",
       "0            0  ['Sentiment classification is an active resear...   \n",
       "1            1  ['User generated content is bringing new aspec...   \n",
       "2            2  ['The Web has become a source of information, ...   \n",
       "3            3  ['In natural language one idea can be conveyed...   \n",
       "4            4  ['Automatic Speech Recognition (ASR) is one of...   \n",
       "\n",
       "   abs_sents_num                                         sent_order  \\\n",
       "0             10  ['background_label', 'background_label', 'back...   \n",
       "1              9  ['background_label', 'background_label', 'back...   \n",
       "2              7  ['background_label', 'background_label', 'meth...   \n",
       "3              5  ['background_label', 'background_label', 'back...   \n",
       "4              9  ['background_label', 'background_label', 'back...   \n",
       "\n",
       "                                    background_sents  background_sent_num  \\\n",
       "0  ['Sentiment classification is an active resear...                    4   \n",
       "1  ['User generated content is bringing new aspec...                    4   \n",
       "2  ['The Web has become a source of information, ...                    2   \n",
       "3  ['In natural language one idea can be conveyed...                    3   \n",
       "4  ['Automatic Speech Recognition (ASR) is one of...                    4   \n",
       "\n",
       "  background_sent_index                                       method_sents  \\\n",
       "0          [0, 1, 2, 3]  ['Small set of seed terms are manually prepare...   \n",
       "1          [0, 1, 2, 3]  ['The proposed framework combines the lexicon ...   \n",
       "2                [0, 1]  ['Thus, this research work designed generic an...   \n",
       "3             [0, 1, 2]  ['Accordingly, we proposed deep learning based...   \n",
       "4          [0, 1, 2, 3]  ['Amharic, Tigrigna, Oromo, and Wolaytta.', 'I...   \n",
       "\n",
       "   method_sent_num method_sent_index  \\\n",
       "0                4      [5, 6, 7, 8]   \n",
       "1                2            [5, 6]   \n",
       "2                3         [2, 3, 5]   \n",
       "3                1               [3]   \n",
       "4                4      [4, 5, 6, 7]   \n",
       "\n",
       "                                        result_sents  result_sent_num  \\\n",
       "0  ['Finally, the lexicon generated in corpus bas...                1   \n",
       "1  ['The system is performing the best of all mod...                2   \n",
       "2  ['The results have also implied that neural ne...                2   \n",
       "3  ['The experiment on limited Amharic NLI datase...                1   \n",
       "4  ['we achieved show that the corpora are usable...                1   \n",
       "\n",
       "  result_sent_index                                    objective_sents  \\\n",
       "0               [9]  ['The intention of this approach is to handle ...   \n",
       "1            [7, 8]  ['For this research, we proposed Amharic negat...   \n",
       "2            [4, 6]                                                 []   \n",
       "3               [4]                                                 []   \n",
       "4               [8]                                                 []   \n",
       "\n",
       "   objective_sent_num objective_sent_index other_sents  other_sent_num  \\\n",
       "0                   1                  [4]          []               0   \n",
       "1                   1                  [4]          []               0   \n",
       "2                   0                   []          []               0   \n",
       "3                   0                   []          []               0   \n",
       "4                   0                   []          []               0   \n",
       "\n",
       "  other_sent_index  \n",
       "0               []  \n",
       "1               []  \n",
       "2               []  \n",
       "3               []  \n",
       "4               []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_result = pd.read_csv('input_ann.csv')\n",
    "stat_result = stat_result.rename(columns={'abs_id':'abstract_id'})\n",
    "stat_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18086, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = pd.merge(total_df, stat_result, how='left', on='abstract_id')\n",
    "combine_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>booktitle</th>\n",
       "      <th>abs_sents</th>\n",
       "      <th>abs_sents_num</th>\n",
       "      <th>sent_order</th>\n",
       "      <th>background_sents</th>\n",
       "      <th>background_sent_num</th>\n",
       "      <th>background_sent_index</th>\n",
       "      <th>...</th>\n",
       "      <th>method_sent_index</th>\n",
       "      <th>result_sents</th>\n",
       "      <th>result_sent_num</th>\n",
       "      <th>result_sent_index</th>\n",
       "      <th>objective_sents</th>\n",
       "      <th>objective_sent_num</th>\n",
       "      <th>objective_sent_index</th>\n",
       "      <th>other_sents</th>\n",
       "      <th>other_sent_num</th>\n",
       "      <th>other_sent_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Corpus based {A}mharic sentiment lexicon gener...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "      <td>['Sentiment classification is an active resear...</td>\n",
       "      <td>10</td>\n",
       "      <td>['background_label', 'background_label', 'back...</td>\n",
       "      <td>['Sentiment classification is an active resear...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[5, 6, 7, 8]</td>\n",
       "      <td>['Finally, the lexicon generated in corpus bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>[9]</td>\n",
       "      <td>['The intention of this approach is to handle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Negation handling for {A}mharic sentiment clas...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "      <td>['User generated content is bringing new aspec...</td>\n",
       "      <td>9</td>\n",
       "      <td>['background_label', 'background_label', 'back...</td>\n",
       "      <td>['User generated content is bringing new aspec...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>['The system is performing the best of all mod...</td>\n",
       "      <td>2</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>['For this research, we proposed Amharic negat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Embedding Oriented Adaptable Semantic Annotati...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "      <td>['The Web has become a source of information, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>['background_label', 'background_label', 'meth...</td>\n",
       "      <td>['The Web has become a source of information, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2, 3, 5]</td>\n",
       "      <td>['The results have also implied that neural ne...</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Similarity and Farness Based Bidirectional Neu...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "      <td>['In natural language one idea can be conveyed...</td>\n",
       "      <td>5</td>\n",
       "      <td>['background_label', 'background_label', 'back...</td>\n",
       "      <td>['In natural language one idea can be conveyed...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>['The experiment on limited Amharic NLI datase...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Large Vocabulary Read Speech Corpora for Four ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Proceedings of the The Fourth Widening Natural...</td>\n",
       "      <td>['Automatic Speech Recognition (ASR) is one of...</td>\n",
       "      <td>9</td>\n",
       "      <td>['background_label', 'background_label', 'back...</td>\n",
       "      <td>['Automatic Speech Recognition (ASR) is one of...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 5, 6, 7]</td>\n",
       "      <td>['we achieved show that the corpora are usable...</td>\n",
       "      <td>1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstract_id                                              title  year  \\\n",
       "0            0  Corpus based {A}mharic sentiment lexicon gener...  2020   \n",
       "1            1  Negation handling for {A}mharic sentiment clas...  2020   \n",
       "2            2  Embedding Oriented Adaptable Semantic Annotati...  2020   \n",
       "3            3  Similarity and Farness Based Bidirectional Neu...  2020   \n",
       "4            4  Large Vocabulary Read Speech Corpora for Four ...  2020   \n",
       "\n",
       "                                           booktitle  \\\n",
       "0  Proceedings of the The Fourth Widening Natural...   \n",
       "1  Proceedings of the The Fourth Widening Natural...   \n",
       "2  Proceedings of the The Fourth Widening Natural...   \n",
       "3  Proceedings of the The Fourth Widening Natural...   \n",
       "4  Proceedings of the The Fourth Widening Natural...   \n",
       "\n",
       "                                           abs_sents  abs_sents_num  \\\n",
       "0  ['Sentiment classification is an active resear...             10   \n",
       "1  ['User generated content is bringing new aspec...              9   \n",
       "2  ['The Web has become a source of information, ...              7   \n",
       "3  ['In natural language one idea can be conveyed...              5   \n",
       "4  ['Automatic Speech Recognition (ASR) is one of...              9   \n",
       "\n",
       "                                          sent_order  \\\n",
       "0  ['background_label', 'background_label', 'back...   \n",
       "1  ['background_label', 'background_label', 'back...   \n",
       "2  ['background_label', 'background_label', 'meth...   \n",
       "3  ['background_label', 'background_label', 'back...   \n",
       "4  ['background_label', 'background_label', 'back...   \n",
       "\n",
       "                                    background_sents  background_sent_num  \\\n",
       "0  ['Sentiment classification is an active resear...                    4   \n",
       "1  ['User generated content is bringing new aspec...                    4   \n",
       "2  ['The Web has become a source of information, ...                    2   \n",
       "3  ['In natural language one idea can be conveyed...                    3   \n",
       "4  ['Automatic Speech Recognition (ASR) is one of...                    4   \n",
       "\n",
       "  background_sent_index  ... method_sent_index  \\\n",
       "0          [0, 1, 2, 3]  ...      [5, 6, 7, 8]   \n",
       "1          [0, 1, 2, 3]  ...            [5, 6]   \n",
       "2                [0, 1]  ...         [2, 3, 5]   \n",
       "3             [0, 1, 2]  ...               [3]   \n",
       "4          [0, 1, 2, 3]  ...      [4, 5, 6, 7]   \n",
       "\n",
       "                                        result_sents result_sent_num  \\\n",
       "0  ['Finally, the lexicon generated in corpus bas...               1   \n",
       "1  ['The system is performing the best of all mod...               2   \n",
       "2  ['The results have also implied that neural ne...               2   \n",
       "3  ['The experiment on limited Amharic NLI datase...               1   \n",
       "4  ['we achieved show that the corpora are usable...               1   \n",
       "\n",
       "  result_sent_index                                    objective_sents  \\\n",
       "0               [9]  ['The intention of this approach is to handle ...   \n",
       "1            [7, 8]  ['For this research, we proposed Amharic negat...   \n",
       "2            [4, 6]                                                 []   \n",
       "3               [4]                                                 []   \n",
       "4               [8]                                                 []   \n",
       "\n",
       "  objective_sent_num objective_sent_index  other_sents other_sent_num  \\\n",
       "0                  1                  [4]           []              0   \n",
       "1                  1                  [4]           []              0   \n",
       "2                  0                   []           []              0   \n",
       "3                  0                   []           []              0   \n",
       "4                  0                   []           []              0   \n",
       "\n",
       "  other_sent_index  \n",
       "0               []  \n",
       "1               []  \n",
       "2               []  \n",
       "3               []  \n",
       "4               []  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df.to_csv('complete.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
